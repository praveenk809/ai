{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cd0850-61d0-4ef4-bebd-4ea391c39e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "- Canberra is the capital of Australia\n",
    "- Is the Canberra capital of Australia"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d74b2f4-d1dd-4cae-8388-ad5ca91744ff",
   "metadata": {},
   "source": [
    "Why syntax analysis?\n",
    "## Word order and meaning\n",
    "- Dog bites man\n",
    "- Man bites dog\n",
    "\n",
    "## Role of stop words\n",
    "- Tendulkar lost to Australia\n",
    "- Tendulkar lost in Australia\n",
    "\n",
    "## Role of morphological forms\n",
    "- Our workers are working hard to make our code work # work\n",
    "\n",
    "## Role POS\n",
    "- My uncle is learning driving (NN) in a driving (ADJ) school\n",
    "\n",
    "## Dependencies\n",
    "- What is the capital of India\n",
    "- what is the name of the country in whose capital india led the UN delegation on climate change?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "250f9ee0-a86e-4bf1-9655-06cb88552271",
   "metadata": {},
   "source": [
    "1. Lexical based tagging\n",
    "\n",
    "corpus: I went for a run/NN.......run/NN.......run/VB.......run/VB.......I run/VB in the morning\n",
    "run => VB (8/10)\n",
    "accuracy: 10%\n",
    "\n",
    "2. Rule based tagging\n",
    "*ing = VB\n",
    "*ous = ADJ\n",
    "\n",
    "3. Probabilistic (stochastic) techniques\n",
    "- Bayes Theorem : P(A|B) = P(A^B)/P(B) = P(B|A) * P(A)/P(B)\n",
    "- 'The high cost' # [DT, JJ, NN]\n",
    "\n",
    "4. Model based tagging (ML, DL to train dataset and use it for predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07bb9a82-0788-4178-92a1-0b8024c969c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3db00158-c848-41de-ae37-6b834356927a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pos_tag in module nltk.tag:\n",
      "\n",
      "pos_tag(tokens, tagset=None, lang='eng')\n",
      "    Use NLTK's currently recommended part of speech tagger to\n",
      "    tag the given list of tokens.\n",
      "    \n",
      "        >>> from nltk.tag import pos_tag\n",
      "        >>> from nltk.tokenize import word_tokenize\n",
      "        >>> pos_tag(word_tokenize(\"John's big idea isn't all that bad.\")) # doctest: +NORMALIZE_WHITESPACE\n",
      "        [('John', 'NNP'), (\"'s\", 'POS'), ('big', 'JJ'), ('idea', 'NN'), ('is', 'VBZ'),\n",
      "        (\"n't\", 'RB'), ('all', 'PDT'), ('that', 'DT'), ('bad', 'JJ'), ('.', '.')]\n",
      "        >>> pos_tag(word_tokenize(\"John's big idea isn't all that bad.\"), tagset='universal') # doctest: +NORMALIZE_WHITESPACE\n",
      "        [('John', 'NOUN'), (\"'s\", 'PRT'), ('big', 'ADJ'), ('idea', 'NOUN'), ('is', 'VERB'),\n",
      "        (\"n't\", 'ADV'), ('all', 'DET'), ('that', 'DET'), ('bad', 'ADJ'), ('.', '.')]\n",
      "    \n",
      "    NB. Use `pos_tag_sents()` for efficient tagging of more than one sentence.\n",
      "    \n",
      "    :param tokens: Sequence of tokens to be tagged\n",
      "    :type tokens: list(str)\n",
      "    :param tagset: the tagset to be used, e.g. universal, wsj, brown\n",
      "    :type tagset: str\n",
      "    :param lang: the ISO 639 code of the language, e.g. 'eng' for English, 'rus' for Russian\n",
      "    :type lang: str\n",
      "    :return: The tagged tokens\n",
      "    :rtype: list(tuple(str, str))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0dd1b7d-b1f9-493d-8e1b-9ec90edab5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('eating', 'VBG')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag([\"eating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e82b0f4-a454-4403-bcfa-71841304960e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('striped', 'JJ'),\n",
       " ('bats', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('hanging', 'VBG'),\n",
       " ('on', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('feet', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('ate', 'NN'),\n",
       " ('best', 'RBS'),\n",
       " ('fruits', 'NNS')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The striped bats were hanging on their feet and ate best fruits\"\n",
    "words = word_tokenize(text)\n",
    "pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "682d1a20-e048-42bb-9fe8-f494928fc19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "v\n",
      "n\n",
      "r\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "print(wordnet.ADJ)\n",
    "print(wordnet.VERB)\n",
    "print(wordnet.NOUN)\n",
    "print(wordnet.ADV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71bbab05-35cb-4b96-8859-368edf70eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith(\"J\"):\n",
    "        return 'a'\n",
    "    elif tag.startswith(\"V\"):\n",
    "        return 'v'\n",
    "    elif tag.startswith(\"N\"):\n",
    "        return 'n'\n",
    "    elif tag.startswith(\"R\"):\n",
    "        return 'r'\n",
    "    else:\n",
    "        return 'n' # default to noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0b79f90-0e72-4f9d-9ca5-4f53774d53d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(\"running\", pos='v') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a111183-bf39-407b-83b7-0eae2226b017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT', 'The'),\n",
       " ('striped', 'JJ', 'striped'),\n",
       " ('bats', 'NNS', 'bat'),\n",
       " ('were', 'VBD', 'be'),\n",
       " ('hanging', 'VBG', 'hang'),\n",
       " ('on', 'IN', 'on'),\n",
       " ('their', 'PRP$', 'their'),\n",
       " ('feet', 'NNS', 'foot'),\n",
       " ('and', 'CC', 'and'),\n",
       " ('ate', 'NN', 'ate'),\n",
       " ('best', 'RBS', 'best'),\n",
       " ('fruits', 'NNS', 'fruit')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def pos_tag_and_lemmatize(text):\n",
    "    words = word_tokenize(text)\n",
    "    pos_tags = pos_tag(words)\n",
    "\n",
    "    lemmas =[]\n",
    "    for word, tag in pos_tags:\n",
    "        lemma = lemmatizer.lemmatize(word, pos=get_wordnet_pos(tag))\n",
    "        lemmas.append((word, tag, lemma))\n",
    "    return lemmas\n",
    "\n",
    "# Example\n",
    "text = \"The striped bats were hanging on their feet and ate best fruits\"\n",
    "result = pos_tag_and_lemmatize(text)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
